{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pearl.bayesnet import from_yaml\n",
    "from pearl.data import VariableData, BayesianNetworkDataset\n",
    "from pearl.common import NodeValueType\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyro.optim import Adam\n",
    "\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we define and train a simple generalized linea model. Let us consider a model with 5 variables. The dependent variable 'E' has discrete parents 'A', 'B' and continuous parents 'C', 'D'. For each combination of discrete parents, 'E' is sampled from a categorical distribution (with 2 categories) obtained by applying a softmax function to linear combinations of the continuous parents 'C', 'D'. The exact data generating mechanism is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "\n",
    "# 'A' and 'B' are sampled from categorical distributions\n",
    "# 'C' and 'D' are sampled from Normal distributions\n",
    "a = torch.distributions.Categorical(torch.tensor([0.3, 0.7])).sample((N,)).float()\n",
    "b = torch.distributions.Categorical(torch.tensor([0.6, 0.4])).sample((N,)).float()\n",
    "c = torch.distributions.Normal(0., 1.).sample((N,)).float()\n",
    "d = torch.distributions.Normal(3, 1.).sample((N,)).float()\n",
    "\n",
    "parents_stack = torch.stack([c,d], dim=-1).unsqueeze(-1).expand(-1, -1, 2)\n",
    "\n",
    "mask1 = torch.eq(a, 0.) & torch.eq(b, 0.)\n",
    "mask2 = torch.eq(a, 0.) & torch.eq(b, 1.)\n",
    "mask3 = torch.eq(a, 1.) & torch.eq(b, 0.)\n",
    "mask4 = torch.eq(a, 1.) & torch.eq(b, 1.)\n",
    "\n",
    "# 'E' is sampled using a generalized linear model.\n",
    "# For each combination of values of 'A' and 'B', we use a softmax function applied to two linear functions of 'C' and 'D' to generate a categorical distribution.\n",
    "# 'E' is finally sampled from this categorical distribution.\n",
    "e = torch.empty((N,))\n",
    "bias = torch.tensor([\n",
    "    [\n",
    "        [\n",
    "            [0.0, 0.0]\n",
    "        ],\n",
    "        [\n",
    "            [0.0, 0.0]\n",
    "        ]\n",
    "    ],\n",
    "    [\n",
    "        [\n",
    "            [0.0, 0.0]\n",
    "        ],\n",
    "        [\n",
    "            [0.0, 0.0]\n",
    "        ]\n",
    "    ],\n",
    "])\n",
    "weights = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            [\n",
    "                [1.0, 1.25],\n",
    "                [1.0, 1.50],\n",
    "            ],\n",
    "            [\n",
    "                [1.0, 1.75],\n",
    "                [1.0, 2.00],\n",
    "            ],\n",
    "        ],\n",
    "        [\n",
    "            [\n",
    "                [2.00, 1.0],\n",
    "                [1.75, 1.0],\n",
    "            ],\n",
    "            [\n",
    "                [1.50, 1.0],\n",
    "                [1.25, 1.0],\n",
    "            ]\n",
    "        ],\n",
    "    ],\n",
    ")\n",
    "\n",
    "e[mask1] = torch.distributions.Categorical(\n",
    "    torch.softmax(\n",
    "        torch.sum(parents_stack * weights[0][0], dim=-2) + bias[0][0], \n",
    "        dim=-1\n",
    "    )\n",
    ").sample().float()[mask1]\n",
    "e[mask2] = torch.distributions.Categorical(\n",
    "    torch.softmax(\n",
    "        torch.sum(parents_stack * weights[0][1], dim=-2) + bias[0][1], \n",
    "        dim=-1\n",
    "    )\n",
    ").sample().float()[mask2]\n",
    "e[mask3] = torch.distributions.Categorical(\n",
    "    torch.softmax(\n",
    "        torch.sum(parents_stack * weights[1][0], dim=-2) + bias[1][0], \n",
    "        dim=-1\n",
    "    )\n",
    ").sample().float()[mask3]\n",
    "e[mask4] = torch.distributions.Categorical(\n",
    "    torch.softmax(\n",
    "        torch.sum(parents_stack * weights[1][1], dim=-2) + bias[1][1], \n",
    "        dim=-1\n",
    "    )\n",
    ").sample().float()[mask4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert a.shape == b.shape == c.shape == d.shape == e.shape == (N,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declarative model specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The declarative specification the model and the graph structure are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:\r\n",
      "  index: 0\r\n",
      "  type: cpu\r\n",
      "encodingVersion: v1.0\r\n",
      "name: glmodel\r\n",
      "plates: {}\r\n",
      "nodes:\r\n",
      "  A:\r\n",
      "    type: CategoricalNodeWithDirichletPrior\r\n",
      "    domain: ['a', 'b']\r\n",
      "    parents: []\r\n",
      "    plates: []\r\n",
      "  B:\r\n",
      "    type: CategoricalNodeWithDirichletPrior\r\n",
      "    domain: ['a', 'b']\r\n",
      "    parents: []\r\n",
      "    plates: []\r\n",
      "  C:\r\n",
      "    type: ContinuousNodeWithNormalDistribution\r\n",
      "    parents: []\r\n",
      "    plates: []\r\n",
      "  D:\r\n",
      "    type: ContinuousNodeWithNormalDistribution\r\n",
      "    parents: []\r\n",
      "    plates: []\r\n",
      "  E:\r\n",
      "    type: GeneralizedLinearNode\r\n",
      "    domain: ['a', 'b']\r\n",
      "    parents: ['A', 'B', 'C', 'D']\r\n",
      "    plates: []\r\n"
     ]
    }
   ],
   "source": [
    "! cat glmodel.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = from_yaml('glmodel.yaml')\n",
    "model.write_dot('glmodel.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.1 (20200629.0846)\n",
       " -->\n",
       "<!-- Title: glmodel Pages: 1 -->\n",
       "<svg width=\"278pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 278.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<title>glmodel</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 274,-112 274,4 -4,4\"/>\n",
       "<!-- D -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>D</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">D</text>\n",
       "</g>\n",
       "<!-- E -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>E</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"135\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">E</text>\n",
       "</g>\n",
       "<!-- D&#45;&gt;E -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>D&#45;&gt;E</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M45.81,-76.81C63,-65.67 88.62,-49.06 107.99,-36.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"109.92,-39.43 116.4,-31.05 106.11,-33.56 109.92,-39.43\"/>\n",
       "</g>\n",
       "<!-- C -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>C</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">C</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;E -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>C&#45;&gt;E</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107.35,-72.76C111.71,-64.28 117.15,-53.71 122.04,-44.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.23,-45.64 126.7,-35.15 119.01,-42.44 125.23,-45.64\"/>\n",
       "</g>\n",
       "<!-- B -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>B</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"171\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">B</text>\n",
       "</g>\n",
       "<!-- B&#45;&gt;E -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>B&#45;&gt;E</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M162.65,-72.76C158.29,-64.28 152.85,-53.71 147.96,-44.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"150.99,-42.44 143.3,-35.15 144.77,-45.64 150.99,-42.44\"/>\n",
       "</g>\n",
       "<!-- A -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>A</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"243\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">A</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;E -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>A&#45;&gt;E</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M224.19,-76.81C207,-65.67 181.38,-49.06 162.01,-36.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"163.89,-33.56 153.6,-31.05 160.08,-39.43 163.89,-33.56\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x14418bc40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphviz.Source.from_file('glmodel.dot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train the model defined using pearl on the generated data and see how well it recovers the parameters of the generalized linear model. First we need to package the tensors as a `BayesianNetworkDataset` and divide it into train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict = {\n",
    "    'A': VariableData(\n",
    "        NodeValueType.CATEGORICAL,\n",
    "        a,\n",
    "        ['a', 'b'],\n",
    "    ),\n",
    "    'B': VariableData(\n",
    "        NodeValueType.CATEGORICAL,\n",
    "        b,\n",
    "        ['a', 'b'],\n",
    "    ),\n",
    "    'C': VariableData(\n",
    "        NodeValueType.CONTINUOUS,\n",
    "        c,\n",
    "    ),\n",
    "    'D': VariableData(\n",
    "        NodeValueType.CONTINUOUS,\n",
    "        d,\n",
    "    ),\n",
    "    'E': VariableData(\n",
    "        NodeValueType.CATEGORICAL,\n",
    "        e,\n",
    "        ['a', 'b'],\n",
    "    )\n",
    "}\n",
    "dataset = BayesianNetworkDataset(variable_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = dataset.split((4000, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will train the model using SVI to optimize the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam({'lr': 0.005, 'betas': (0.95, 0.995)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 997/10000 [00:14<02:12, 67.89it/s]svi_step: 1000\n",
      "elbo: 18502.301599681377\n",
      " 20%|█▉        | 1999/10000 [00:29<01:57, 68.36it/s]svi_step: 2000\n",
      "elbo: 18481.76528418064\n",
      " 30%|██▉       | 2996/10000 [00:44<01:40, 69.37it/s]svi_step: 3000\n",
      "elbo: 18248.345020353794\n",
      " 40%|███▉      | 3999/10000 [00:58<01:36, 62.00it/s]svi_step: 4000\n",
      "elbo: 18257.90289145708\n",
      " 50%|████▉     | 4998/10000 [01:13<01:13, 68.49it/s]svi_step: 5000\n",
      "elbo: 18284.167265236378\n",
      " 60%|█████▉    | 5998/10000 [01:28<00:59, 67.00it/s]svi_step: 6000\n",
      "elbo: 18270.44609349966\n",
      " 70%|██████▉   | 6994/10000 [01:42<00:43, 69.36it/s]svi_step: 7000\n",
      "elbo: 18235.830620646477\n",
      " 80%|███████▉  | 7997/10000 [01:57<00:29, 68.75it/s]svi_step: 8000\n",
      "elbo: 18241.27462619543\n",
      " 90%|████████▉ | 8992/10000 [02:11<00:14, 69.53it/s]svi_step: 9000\n",
      "elbo: 18224.82104128599\n",
      "100%|█████████▉| 9994/10000 [02:26<00:00, 69.68it/s]svi_step: 10000\n",
      "elbo: 18239.26932001114\n",
      "100%|██████████| 10000/10000 [02:26<00:00, 68.31it/s]\n",
      "training time: 146.40990614891052\n"
     ]
    }
   ],
   "source": [
    "losses=model.train(\n",
    "    dataset=train_dataset,\n",
    "    optimizer=adam,\n",
    "    num_steps=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14467cbe0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2872, 0.7128], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# CPD over A is Cat(0.3, 0.7 )\n",
    "alphas = model.get_node_object('A').guide_alpha\n",
    "print(alphas / torch.sum(alphas, dim=-1, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5991, 0.4009], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# CPD over B is Cat(0.6, 0.4 )\n",
    "alphas = model.get_node_object('B').guide_alpha\n",
    "print(alphas / torch.sum(alphas, dim=-1, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0073, requires_grad=True)\n",
      "tensor(1.0071, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# CPD over C is N(0., 1.)\n",
    "node_object = model.get_node_object('C')\n",
    "mean = node_object.guide_mean_mean\n",
    "scale = node_object.guide_scale\n",
    "print(mean)\n",
    "print(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0096, requires_grad=True)\n",
      "tensor(0.9974, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# CPD over C is N(3., 1.)\n",
    "node_object = model.get_node_object('D')\n",
    "mean = node_object.guide_mean_mean\n",
    "scale = node_object.guide_scale\n",
    "print(mean)\n",
    "print(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1524,  0.1524],\n",
      "         [ 0.4244, -0.4244]],\n",
      "\n",
      "        [[ 0.1649, -0.1648],\n",
      "         [ 0.0865, -0.0865]]], requires_grad=True)\n",
      "tensor([[[[-0.1215,  0.1215],\n",
      "          [-0.2178,  0.2178]],\n",
      "\n",
      "         [[-0.4403,  0.4403],\n",
      "          [-0.7369,  0.7369]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5110, -0.5110],\n",
      "          [ 0.3410, -0.3410]],\n",
      "\n",
      "         [[ 0.2721, -0.2721],\n",
      "          [ 0.1013, -0.1013]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# CPD over E\n",
    "node_object = model.get_node_object('E')\n",
    "node_weights = node_object.guide_weights_mean\n",
    "node_bias = node_object.guide_bias_mean\n",
    "print(node_bias)\n",
    "print(node_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bias vector is close to zero since we did not use any bias term in the data generating mechanism for 'E'. While the exact weights may not be identical, its important that they induce the same categorical distribution through the softmax function. We verify that by computing the softmax of the two weight tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3208, 0.6792],\n",
      "         [0.1480, 0.8520]],\n",
      "\n",
      "        [[0.8520, 0.1480],\n",
      "         [0.6792, 0.3208]]])\n",
      "tensor([[[0.2722, 0.7278],\n",
      "         [0.1816, 0.8184]],\n",
      "\n",
      "        [[0.8843, 0.1157],\n",
      "         [0.7150, 0.2850]]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.softmax(torch.sum(weights, dim=-2), dim=-1))\n",
    "print(torch.softmax(torch.sum(node_weights, dim=-2) + node_bias, dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the trained model to answer various probabilistic queries. The standard query is to predict 'E' conditioned on the remaining variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.826\n"
     ]
    }
   ],
   "source": [
    "_, map_assignments, _ = model.predict(\n",
    "    dataset=test_dataset,\n",
    "    target_variables=['E'],\n",
    ")\n",
    "\n",
    "acc = float(torch.eq(test_dataset['E'], map_assignments['E']).sum())\n",
    "print(f'accuracy is {acc / len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
